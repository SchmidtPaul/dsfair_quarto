{
  "hash": "46d076d81ea9212c8adbecdd7fe27e8d",
  "result": {
    "markdown": "---\ntitle: \"Model Diagnostics\"\ndate: 2022-11-11\n---\n\n\n\n\n\n# What is it?\n\nMost statistical methods and all statistical models make certain assumptions (about the data generating process), and (test) results will be meaningless or misleading if theses assumptions do not hold. Therefore, model diagnostics should be used to check how well the assumptions of any given model are met.\n\n# Which assumptions?\n\nAs an example, we will specifically address the assumptions that ANOVA (analysis of variance) has. It makes sense to choose ANOVA because of its popularity and relevance in the chapters of this website. The following model will serve as an example throughout the chapter:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(weight ~ group, data = PlantGrowth)\n```\n:::\n\n\n\nNote that both the `PlantGrowth` data and the `lm()` function come with base R and thus don't need any extra imports. In a next step, we would want to run `anova(mod)`. While all of the tests and plots that follow could also be produced with base R, I choose to use other packages here that I personally prefer for convenience and/or functionality reasons.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# (install &) load packages\npacman::p_load(\n  easystats, \n  olsrr,\n  qqplotr, \n  tidyverse\n  )\n```\n:::\n\n\n\n## Independence\n\n**Assumption: Individual observations are independent of each other (as opposed to dependent/correlated).**\n\nModel diagnostics are actually not used to verify this specific assumption. Instead, this assumption is justified if proper randomization was applied as part of the experimental design. Keep in mind, that there are indeed non-classical scenarios like repeated measures over time or certain experimental designs where observations are not (assumed to be) independent, but these are not covered in this chapter.\n\n## Normality\n\n**Assumption: The errors follow a normal distribution.**\n\nA model's errors cannot be directly observed, but are estimated by their residuals; these residuals can be used for checking normality.\n\n::: callout-important\n## Yes residuals - not data!\n\nUnfortunately, it is more common than it should be that people check whether their raw data (i.e. their response variable, e.g. yield) is normally distributed. This is not constructive. Instead, the model's residuals should be checked for normality. Please see section \"4 \\| ANSWERING QUESTION 1\" in [@kozak2018] for details.\n:::\n\n### QQ plot\n\nApproximate normality can be assumed, if the dots in a QQ plot look close to a straight line. Kozak & Piepho [-@kozak2018] point out that *when it comes to checking normality, we need to be clear that we will never be able to check whether indeed the distribution is fully normal; instead, we should check whether it is approximately normal*.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod %>% \n  check_normality() %>% \n  plot(type = \"qq\")\n```\n\n::: {.cell-output-display}\n![](modeldiagnostics_files/figure-pdf/unnamed-chunk-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n### Tests\n\nAs explained [further below](modeldiagnostics.qmd#plots-instead-of-tests), I do not embrace using statistical tests to check assumptions, but instead suggest using the diagnostic plot above. However, for completeness I still provide the following information:\n\nThere are multiple statistical tests for detecting a violation of the normality assumption. A p-value \\< 0.05 would suggest such a violation:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols_test_normality(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.custom-output}\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.9661         0.4379 \nKolmogorov-Smirnov        0.1101         0.8215 \nCramer-von Mises          3.6109         0.0000 \nAnderson-Darling          0.3582         0.4299 \n-----------------------------------------------\n```\n:::\n:::\n\n\n\n## Variance homogeneity\n\n**Assumption: The error variance is the same at any set of predictor values.**\n\nAlso referred to as *homoscedasticity* (i.e. the opposite of *heteroscedasticity*)\n\n### Res-Pred Plot\n\nWhile this plot does not seem to have an established name, it always has raw/standardized/studentized residuals on the y axis and fitted/predicted values on the x axis. Variance homogeneity can be assumed if the residuals form an approximate horizontal band around the 0 line indicating homogeneity of error variance.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod %>% \n  check_heteroscedasticity() %>% \n  plot()\n```\n\n::: {.cell-output-display}\n![](modeldiagnostics_files/figure-pdf/unnamed-chunk-6-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n### Tests\n\nAs explained [further below](modeldiagnostics.qmd#plots-instead-of-tests), I do not embrace using statistical tests to check assumptions, but instead suggest using the diagnostic plot above. However, for completeness I still provide the following information:\n\nThere are multiple statistical tests for detecting a violation of the variance homogeneity assumption. A p-value \\< 0.05 would suggest such a violation:\n\n::: columns\n::: {.column width=\"49%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols_test_breusch_pagan(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.custom-output}\n\n Breusch Pagan Test for Heteroskedasticity\n -----------------------------------------\n Ho: the variance is constant            \n Ha: the variance is not constant        \n\n               Data                \n ----------------------------------\n Response : weight \n Variables: fitted values of weight \n\n        Test Summary          \n -----------------------------\n DF            =    1 \n Chi2          =    3.000303 \n Prob > Chi2   =    0.08324896 \n```\n:::\n:::\n\n\n:::\n\n::: {.column width=\"2%\"}\n:::\n\n::: {.column width=\"49%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols_test_bartlett(\n  data = PlantGrowth, \n  \"weight\", \n  group_var = \"group\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.custom-output}\n\n    Bartlett's Test of Homogenity of Variances    \n------------------------------------------------\nHo: Variances are equal across groups\nHa: Variances are unequal for atleast two groups\n\n        Test Summary         \n ----------------------------\n DF            =    2 \n Chi2          =    2.878592 \n Prob > Chi2   =    0.2370946 \n```\n:::\n:::\n\n\n:::\n:::\n\n## Linearity\n\n**Assumption: The response can be written as a linear combination of the predictors.**\n\nThis assumption can also be checked via the Res-Pred-plot from the *Variance homogeneity* section above. It can assumed to be met if the residuals spread randomly around the 0 line. In other words: At any fitted value, the mean of the residuals should be roughly 0. If this is the case, the linearity assumption is valid. I am not aware of any statistical tests for linearity.\n\n# Plots instead of tests\n\nWhen it comes to diagnosing models, one may separate most approaches into two general categories: **significance tests** and **diagnostic plots**. Personally, I follow Kozak & Piepho [-@kozak2018], who show that *\"residual plots are better for checking ANOVA assumptions than statistical tests\"*. Here are two key sections from their publication:\n\n> According to many authors (e.g., Atkinson, 1987; Belsley, Kuh, & Welsch, 2005; Kozak, 2009; Moser & Stevens, 1992; Quinn & Keough, 2002; Rasch, Kubinger, & Moder, 2011; Schucany & Ng, 2006), significance tests should not be used for checking assumptions. Diagnostic residual plots are a better choice. On such diagnostic plots, we can identify untypical observations, heterogeneous within-treatment variances, and lack of normality of the residuals (and thus, of the dependent variable within treatments).\n>\n> [...]\n>\n> There are two possible reasons for the overuse of statistical\ntests to check assumptions. First, many researchers base their\nknowledge on books first published 40 years ago or earlier. Back\nthen, using statistical tests was relatively simple while using diagnostic plots was difficult; thus, these books advised the former, often\neven not mentioning the latter. Second, most statistical software\noffers statistical tests for checking assumptions as a default. Using\ndefault tests is simple, so users use them. However, we explained\nwhy we think that significance tests are not a good way of checking\nassumptions (in general, not only for ANOVA). First of all, with large\nsamples (a very desirable situation) we risk that even small (and irrelevant) departures from the null hypothesis (which states that the\nassumption is met) will be detected as significant, and so we would\nneed to reject the hypothesis and state that the assumption is not\nmet. With small samples, the situation is opposite: much larger (and\nimportant) departures would not be found significant. Thus, our\nadvice is to use diagnostic plots instead of hypothesis testing to\ncheck ANOVA assumptions.\n\n# TO DO\n\n- help to judge plots\n- mention linearity\n- deal with unruly residuals\n\n::: custom-callout-addref\n\n**General**\n\n-   What's normal anyway? Residual plots are more telling than significance tests when checking ANOVA assumptions [@kozak2018]\n-   [Chapter 13 Model Diagnostics](https://book.stat420.org/model-diagnostics.html) in Applied Statistics with R (Dalpiaz, 2022)\n-   [Chapter 8 Model Diagnostics](https://bookdown.org/marklhc/notes_bookdown/model-diagnostics.html) in Course Handouts for Bayesian Data Analysis (Lai, 2019)\n-   ðŸ‡©ðŸ‡ª [Verbleibende Plots interpretieren, um Ihre Regression zu verbessern](https://www.qualtrics.com/support/de/stats-iq/analyses/regression-guides/interpreting-residual-plots-improve-regression/?rid=langMatch&prevsite=en&newsite=de&geo=DE&geomatch=)\n-   [{olsrr}](https://olsrr.rsquaredacademy.com/)\n\n**Normality**\n\n-   [R Tutorial: Normal Probability Plot of Residuals](www.r-tutor.com/elementary-statistics/simple-linear-regression/normal-probability-plot-residuals)\n-   For this specific purpose, QQ plots may also be called [Normal probability plots](https://www.wikiwand.com/en/Normal_probability_plot)\n-   [{qqplotr}](https://cran.r-project.org/web/packages/qqplotr/vignettes/introduction.html)\n\n**Homoscedasticity**\n\n-    [Documentation on tests from {olsrr}](https://olsrr.rsquaredacademy.com/articles/heteroskedasticity.html)\n-    Wikipedia article on [Homoscedasticity and heteroscedasticity](https://www.wikiwand.com/en/Homoscedasticity%20and%20heteroscedasticity)\n\n:::\n",
    "supporting": [
      "modeldiagnostics_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}